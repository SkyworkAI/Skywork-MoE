<!-- <div align="center">
<h1>
  âœ¨Skywork
</h1>
</div> -->
<div align="center"><img src="misc/skywork_logo.jpeg" width="550"/></div>

<p align="center">
ğŸ¤— <a href="https://huggingface.co/Skywork" target="_blank">Hugging Face</a> â€¢ ğŸ¤– <a href="https://modelscope.cn/organization/Skywork" target="_blank">ModelScope</a> â€¢ ğŸ‘¾ <a href="https://wisemodel.cn/organization/Skywork" target="_blank">Wisemodel</a> â€¢ ğŸ’¬ <a href="https://github.com/SkyworkAI/Skywork/blob/main/misc/wechat.png?raw=true" target="_blank">WeChat</a>â€¢ ğŸ“œ<a href="http://arxiv.org/abs/2310.19341" target="_blank">Tech Report</a>
</p>

<div align="center">

[![GitHub Stars](https://img.shields.io/github/stars/SkyworkAI/Skywork-MoE)](https://github.com/SkyworkAI/Skywork-MoE/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/SkyworkAI/Skywork-MoE)](https://github.com/SkyworkAI/Skywork-MoE/fork)
</div>

<div align="center">

</div>


# é¡¹ç›®ä»‹ç»

Skywork-MoE æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½çš„ä¸“å®¶æ··åˆï¼ˆMoEï¼‰æ¨¡å‹ï¼Œæ‹¥æœ‰1460äº¿å‚æ•°ã€16ä¸ªä¸“å®¶å’Œ220äº¿æ¿€æ´»å‚æ•°ã€‚è¯¥æ¨¡å‹æ˜¯åŸºäºæˆ‘ä»¬ç°æœ‰çš„Skywork-13Bæ¨¡å‹çš„Denseæ£€æŸ¥ç‚¹åˆå§‹åŒ–çš„ã€‚

æˆ‘ä»¬å¼•å…¥äº†ä¸¤é¡¹åˆ›æ–°æŠ€æœ¯ï¼šGating Logit Normalizationï¼Œå¢å¼ºä¸“å®¶å¤šæ ·æ€§ï¼›Adaptive Auxiliary Loss Coefficientsï¼Œå…è®¸å¯¹è¾…åŠ©æŸå¤±ç³»æ•°è¿›è¡Œå±‚çº§è°ƒæ•´ã€‚

Skywork-MoE å±•ç¤ºå‡ºä¸å‚æ•°æ›´å¤šæˆ–æ¿€æ´»å‚æ•°æ›´å¤šçš„æ¨¡å‹ï¼ˆå¦‚Grok-1ã€DBRXã€Mistral 8*22 å’Œ Deepseek-V2ï¼‰ç›¸å½“æˆ–æ›´ä¼˜çš„æ€§èƒ½ã€‚

# æ–°é—»å’Œæ›´æ–°
* 2024.6.3  æˆ‘ä»¬å‘å¸ƒäº† **Skywork-MoE-Base** æ¨¡å‹ã€‚

# ç›®å½•

- [â˜ï¸ä¸‹è½½é“¾æ¥](#ä¸‹è½½é“¾æ¥)
- [ğŸ‘¨â€ğŸ’»åŸºå‡†æµ‹è¯•ç»“æœ](#åŸºå‡†æµ‹è¯•ç»“æœ)
- [ğŸ†Hugging Faceæ¨¡å‹æ¨ç†æ¼”ç¤º](#Hugging-Faceæ¨¡å‹æ¨ç†æ¼”ç¤º)
- [ğŸ“•vLLMæ¨¡å‹æ¨ç†æ¼”ç¤º](#vLLMæ¨¡å‹æ¨ç†æ¼”ç¤º)
- [âš ï¸å£°æ˜å’Œè®¸å¯åè®®](#å£°æ˜å’Œè®¸å¯åè®®)
- [ğŸ¤è”ç³»æˆ‘ä»¬å’Œå¼•ç”¨](#è”ç³»æˆ‘ä»¬å’Œå¼•ç”¨)


# ä¸‹è½½é“¾æ¥

|         |                                 HuggingFace æ¨¡å‹                                 |                                  ModelScope æ¨¡å‹                                  |                                Wisemodel æ¨¡å‹                                |
|:-------:|:------------------------------------------------------------------------------:|:-------------------------------------------------------------------------------:|:--------------------------------------------------------------------------:|
| **Skywork-MoE-Base**     |     ğŸ¤— [Skywork-MoE-Base](https://huggingface.co/Skywork/Skywork-MoE-Base)     | ğŸ¤–[Skywork-MoE-Base](https://www.modelscope.cn/models/skywork/Skywork-MoE-base) | ğŸ‘¾[Skywork-MoE-Base](https://wisemodel.cn/models/Skywork/Skywork-MoE-base) |
| **Skywork-MoE-Base-FP8**  | ğŸ¤— [Skywork-MoE-Base-FP8](https://huggingface.co/Skywork/Skywork-MoE-Base-FP8) |                                       ğŸ¤–                                        |                                     ğŸ‘¾                                     |
| **Skywork-MoE-Chat** | ğŸ˜Š [Coming Soon]() | ğŸ¤– | ğŸ‘¾ |

# åŸºå‡†æµ‹è¯•ç»“æœ

æˆ‘ä»¬åœ¨å„ç§çƒ­é—¨åŸºå‡†æµ‹è¯•ï¼ˆåŒ…æ‹¬C-Evalã€MMLUã€CMMLUã€GSM8Kã€MATHå’ŒHumanEvalï¼‰ä¸Šè¯„ä¼°äº†Skywork-MoE-Baseæ¨¡å‹ã€‚
<img src="misc/skywork_moe_base_evaluation.png" alt="Image" width="600" height="280">

# Hugging Faceæ¨¡å‹æ¨ç†æ¼”ç¤º

## åŸºç¡€æ¨¡å‹æ¨ç†

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨HuggingFaceåœ¨8xA100/A800æˆ–æ›´é«˜çš„GPUç¡¬ä»¶é…ç½®ä¸Šè¿›è¡ŒSkywork-MoE-Baseï¼ˆ16x13Bè§„æ¨¡ï¼‰æ¨¡å‹çš„æ¨ç†ã€‚

```python

from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained("Skywork/Skywork-MoE-Base", trust_remote_code=True, device_map='auto')
tokenizer = AutoTokenizer.from_pretrained("Skywork/Skywork-MoE-Base", trust_remote_code=True)

inputs = tokenizer('é™•è¥¿çš„çœä¼šæ˜¯è¥¿å®‰', return_tensors='pt').to(model.device)
response = model.generate(inputs.input_ids, max_length=128)
print(tokenizer.decode(response.cpu()[0], skip_special_tokens=True))
"""
é™•è¥¿çš„çœä¼šæ˜¯è¥¿å®‰ã€‚
è¥¿å®‰ï¼Œå¤ç§°é•¿å®‰ã€é•äº¬ï¼Œæ˜¯é™•è¥¿çœä¼šã€å‰¯çœçº§å¸‚ã€å…³ä¸­å¹³åŸåŸå¸‚ç¾¤æ ¸å¿ƒåŸå¸‚ã€ä¸ç»¸ä¹‹è·¯èµ·ç‚¹åŸå¸‚ã€â€œä¸€å¸¦ä¸€è·¯â€æ ¸å¿ƒåŒºã€ä¸­å›½è¥¿éƒ¨åœ°åŒºé‡è¦çš„ä¸­å¿ƒåŸå¸‚ï¼Œå›½å®¶é‡è¦çš„ç§‘ç ”ã€æ•™è‚²ã€å·¥ä¸šåŸºåœ°ã€‚
è¥¿å®‰æ˜¯ä¸­å›½å››å¤§å¤éƒ½ä¹‹ä¸€ï¼Œè”åˆå›½ç§‘æ•™æ–‡ç»„ç»‡äº1981å¹´ç¡®å®šçš„â€œä¸–ç•Œå†å²ååŸâ€ï¼Œç¾åª’è¯„é€‰çš„ä¸–ç•Œåå¤§å¤éƒ½ä¹‹ä¸€ã€‚åœ°å¤„å…³ä¸­å¹³åŸä¸­éƒ¨ï¼ŒåŒ—æ¿’æ¸­æ²³ï¼Œå—ä¾ç§¦å²­ï¼Œå…«æ°´æ¶¦é•¿å®‰ã€‚ä¸‹è¾–11åŒº2å¿å¹¶ä»£ç®¡è¥¿
"""

inputs = tokenizer('é™•è¥¿çš„çœä¼šæ˜¯è¥¿å®‰ï¼Œç”˜è‚ƒçš„çœä¼šæ˜¯å…°å·ï¼Œæ²³å—çš„çœä¼šæ˜¯éƒ‘å·', return_tensors='pt').to(model.device)
response = model.generate(inputs.input_ids, max_length=128)
print(tokenizer.decode(response.cpu()[0], skip_special_tokens=True))
"""
é™•è¥¿çš„çœä¼šæ˜¯è¥¿å®‰ï¼Œç”˜è‚ƒçš„çœä¼šæ˜¯å…°å·ï¼Œæ²³å—çš„çœä¼šæ˜¯éƒ‘å·ï¼Œæ¹–åŒ—çš„çœä¼šæ˜¯æ­¦æ±‰ï¼Œæ¹–å—çš„çœä¼šæ˜¯é•¿æ²™ï¼Œå®‰å¾½çš„çœä¼šæ˜¯åˆè‚¥ï¼Œæ±Ÿè¥¿çš„çœä¼šæ˜¯å—æ˜Œï¼Œæ±Ÿè‹çš„çœä¼šæ˜¯å—äº¬ï¼Œæµ™æ±Ÿçš„çœä¼šæ˜¯æ­å·ï¼Œç¦å»ºçš„çœä¼šæ˜¯ç¦å·ï¼Œå¹¿ä¸œçš„çœä¼šæ˜¯å¹¿å·ï¼Œå¹¿è¥¿çš„çœä¼šæ˜¯å—å®ï¼Œå››å·çš„çœä¼šæ˜¯æˆéƒ½ï¼Œè´µå·çš„çœä¼šæ˜¯è´µé˜³ï¼Œäº‘å—çš„çœä¼šæ˜¯æ˜†æ˜ï¼Œå±±è¥¿çš„çœä¼šæ˜¯å¤ªåŸï¼Œå±±ä¸œçš„çœä¼šæ˜¯æµå—ï¼Œæ²³åŒ—çš„çœä¼šæ˜¯çŸ³å®¶åº„ï¼Œè¾½å®çš„çœä¼šæ˜¯æ²ˆé˜³ï¼Œå‰æ—çš„çœä¼šæ˜¯é•¿æ˜¥ï¼Œé»‘é¾™æ±Ÿçš„
"""

```


# vLLMæ¨¡å‹æ¨ç†æ¼”ç¤º

## åŸºäºvLLMçš„å¿«é€Ÿå¯åŠ¨

æˆ‘ä»¬æä¾›äº†ä¸€ç§åŸºäºvllmå¿«é€Ÿéƒ¨ç½²Skywork-MoE-Baseæ¨¡å‹çš„æ–¹æ³•ã€‚

åœ¨fp8ç²¾åº¦ä¸‹ï¼Œä½ åªéœ€8*4090å³å¯è¿è¡ŒSkywork-MoE-Baseã€‚

ä½ å¯ä»¥åœ¨[`vllm`](https://github.com/SkyworkAI/vllm)ä¸­è·å–æºä»£ç ã€‚

ä½ å¯ä»¥åœ¨[`Skywork-MoE-Base-FP8`](https://huggingface.co/Skywork/Skywork-MoE-Base-FP8)ä¸­è·å–fp8æ¨¡å‹ã€‚

### åŸºäºæœ¬åœ°ç¯å¢ƒ

ç”±äºpytorchä»…åœ¨nightlyç‰ˆæœ¬ä¸­æ”¯æŒ4090ä½¿ç”¨fp8ç²¾åº¦ï¼Œä½ éœ€è¦å®‰è£…ç›¸åº”æˆ–æ›´æ–°ç‰ˆæœ¬çš„pytorchã€‚

``` shell
# for cuda12.1
pip3 install --pre torch pytorch-triton --index-url https://download.pytorch.org/whl/nightly/cu121
# for cuda12.4
pip3 install --pre torch pytorch-triton --index-url https://download.pytorch.org/whl/nightly/cu124
```

è¿˜éœ€è¦å®‰è£…å…¶å®ƒä¸€äº›ä¾èµ–ï¼š

```shell
MAX_JOBS=8 pip3 install git+https://github.com/facebookresearch/xformers.git # éœ€è¦ç­‰å¾…è¾ƒé•¿æ—¶é—´
pip3 install vllm-flash-attn --no-deps
```

ç„¶åå…‹éš†skyworkæä¾›çš„[`vllm`](https://github.com/SkyworkAI/vllm)ï¼š

``` shell
git clone https://github.com/SkyworkAI/vllm.git
cd vllm
```

ç„¶åç¼–è¯‘å¹¶å®‰è£…vllmï¼š

``` shell
pip3 install -r requirements-build.txt
pip3 install -r requirements-cuda.txt
MAX_JOBS=8 python3 setup.py install
```

### åŸºäºdocker

ä½ å¯ä»¥ä½¿ç”¨skyworkæä¾›çš„dockeré•œåƒç›´æ¥è¿è¡ŒåŸºäºvllmçš„æ¨ç†ï¼š

```shell
docker pull registry.cn-wulanchabu.aliyuncs.com/triple-mu/skywork-moe-vllm:v1
```

ç„¶åå¯åŠ¨å®¹å™¨å¹¶è®¾ç½®æ¨¡å‹è·¯å¾„å’Œå·¥ä½œç›®å½•ã€‚

```shell
model_path="Skywork/Skywork-MoE-Base-FP8"
workspace=${PWD}

docker run \
    --runtime nvidia \
    --gpus all \
    -it \
    --rm \
    --shm-size=1t \
    --ulimit memlock=-1 \
    --privileged=true \
    --ulimit stack=67108864 \
    --ipc=host \
    -v ${model_path}:/Skywork-MoE-Base-FP8 \
    -v ${workspace}:/workspace \
    registry.cn-wulanchabu.aliyuncs.com/triple-mu/skywork-moe-vllm:v1
```

ç°åœ¨ï¼Œä½ å¯ä»¥è¿è¡Œ Skywork MoE æ¨¡å‹æ¥ä½“éªŒä¸€ä¸‹ï¼

### æ–‡æœ¬è¡¥å…¨

``` python
from vllm import LLM, SamplingParams

model_path = 'Skywork/Skywork-MoE-Base-FP8'
prompts = [
    "The president of the United States is",
    "The capital of France is",
]

sampling_params = SamplingParams(temperature=0.3, max_tokens=256)

llm = LLM(
    model=model_path,
    quantization='fp8',
    kv_cache_dtype='fp8',
    tensor_parallel_size=8,
    gpu_memory_utilization=0.95, 
    enforce_eager=True,
    trust_remote_code=True,
)

outputs = llm.generate(prompts, sampling_params)

for output in outputs:
    prompt = output.prompt
    generated_text = output.outputs[0].text
    print(f"Prompt: {prompt!r}, Generated text: {generated_text!r}")
```


# å£°æ˜å’Œè®¸å¯åè®®


## å£°æ˜

æˆ‘ä»¬åœ¨æ­¤å£°æ˜ï¼ŒSkyworkæ¨¡å‹ä¸å¾—ç”¨äºä»»ä½•å¨èƒå›½å®¶æˆ–ç¤¾ä¼šå®‰å…¨çš„æ´»åŠ¨æˆ–å‚ä¸éæ³•è¡Œä¸ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¦æ±‚ç”¨æˆ·åœ¨æ²¡æœ‰è¿›è¡Œé€‚å½“çš„å®‰å…¨å®¡æŸ¥å’Œå¤‡æ¡ˆçš„æƒ…å†µä¸‹ï¼Œä¸è¦å°†Skyworkæ¨¡å‹ç”¨äºäº’è”ç½‘æœåŠ¡ã€‚æˆ‘ä»¬å¸Œæœ›æ‰€æœ‰ç”¨æˆ·éµå®ˆè¿™ä¸€åŸåˆ™ï¼Œä»¥ç¡®ä¿æŠ€æœ¯è¿›æ­¥åœ¨ä¸€ä¸ªå—ç›‘ç®¡å’Œåˆæ³•çš„ç¯å¢ƒä¸­è¿›è¡Œã€‚

æˆ‘ä»¬å·²å°½æœ€å¤§åŠªåŠ›ç¡®ä¿åœ¨æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ•°æ®çš„åˆè§„æ€§ã€‚ç„¶è€Œï¼Œå°½ç®¡æˆ‘ä»¬ä»˜å‡ºäº†å¤§é‡åŠªåŠ›ï¼Œç”±äºæ¨¡å‹å’Œæ•°æ®çš„å¤æ‚æ€§ï¼Œä»å¯èƒ½å­˜åœ¨ä¸å¯é¢„æµ‹çš„é£é™©å’Œé—®é¢˜ã€‚å› æ­¤ï¼Œå¦‚æœç”±äºä½¿ç”¨Skyworkå¼€æºæ¨¡å‹è€Œå¼•å‘çš„ä»»ä½•é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ•°æ®å®‰å…¨é—®é¢˜ã€èˆ†è®ºé£é™©æˆ–å› æ¨¡å‹è¢«è¯¯å¯¼ã€æ»¥ç”¨ã€ä¼ æ’­æˆ–ä¸å½“åˆ©ç”¨è€Œäº§ç”Ÿçš„ä»»ä½•é£é™©å’Œé—®é¢˜ï¼Œæˆ‘ä»¬å°†ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚

## è®¸å¯åè®®

Skyworkæ¨¡å‹çš„ç¤¾åŒºä½¿ç”¨éœ€è¦éµå®ˆ [Skyworkç¤¾åŒºè®¸å¯](https://github.com/SkyworkAI/Skywork-MoE/blob/main/Skywork%20Community%20License.pdf)ã€‚Skyworkæ¨¡å‹æ”¯æŒå•†ä¸šä½¿ç”¨ã€‚å¦‚æœæ‚¨è®¡åˆ’å°†Skyworkæ¨¡å‹æˆ–å…¶è¡ç”Ÿå“ç”¨äºå•†ä¸šç›®çš„ï¼Œæ‚¨å¿…é¡»éµå®ˆ [Skyworkç¤¾åŒºè®¸å¯](https://github.com/SkyworkAI/Skywork-MoE/blob/main/Skywork%20Community%20License.pdf)ä¸­çš„æ¡æ¬¾å’Œæ¡ä»¶ã€‚

  

[ã€ŠSkywork æ¨¡å‹ç¤¾åŒºè®¸å¯åè®®ã€‹]:https://github.com/SkyworkAI/Skywork-MoE/blob/main/Skywork%20æ¨¡å‹ç¤¾åŒºè®¸å¯åè®®.pdf


[skywork-opensource@kunlun-inc.com]: mailto:skywork-opensource@kunlun-inc.com

# è”ç³»æˆ‘ä»¬å’Œå¼•ç”¨
å¦‚æœä½ è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œæœ‰å¸®åŠ©ï¼Œè¯·éšæ„å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡~
```
@misc{wei2024skywork,
      title={Skywork-MoE: A Deep Dive into Training Techniques for Mixture-of-Experts Language Models}, 
      author={Tianwen Wei, Bo Zhu, Liang Zhao, Cheng Cheng, Biye Li, Weiwei LÃ¼, Peng Cheng, Jianhao Zhang, Xiaoyu Zhang, Liang Zeng, Xiaokun Wang, Yutuan Ma, Rui Hu, Shuicheng Yan, Han Fang, Yahui Zhou},
      year={2024},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```
